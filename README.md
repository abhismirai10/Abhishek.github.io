# Portfolio

---

**Robotics Engineer | Robotics, Automation & Manufacturing | Melbourne, Florida**

---

## About Me
I am an innovative robotics engineer with over two years of experience in **robotics**, **automation**, and **manufacturing**, integrating advanced robotics programming and mechanical design. With a strong focus on **artificial intelligence**, **computer vision**, and **robotic manipulation**, I specialize in developing intelligent, adaptable robotic systems. My passion lies in harnessing cutting-edge technologies to push the boundaries of what’s possible, bridging the gap between simulation and real-world applications.

---

## Contact
**Phone:** +1 434-569-9343 | **Email:** [abhismirai10@gmail.com](mailto:abhismirai10@gmail.com)
**LinkedIn:** [Abhishek Chothani](https://www.linkedin.com/in/abhishek-chothani10/) | **GitHub:** [abhismirai10](https://github.com/abhismirai10) | **YouTube:** [@abhismirai10](https://www.youtube.com/@abhismirai10)

---
## Research Highlights

### End-to-End Learning for Low-Cost Robotic Manipulation
### Research Assistant – NEural TransmissionS (NETS) Lab  
*(Jan 2024 – Dec 2024, Melbourne, Florida)*  
- Focus: Bridging the gap between traditional and learning-based robotics approaches.
- Key Contributions:
  - **Classical Robotics Pipeline**:
    - Developed a robust **pick-and-place pipeline** using the Drake framework and KUKA iiwa robot.
    - Highlighted limitations like kinematic singularities and lack of perception integration.
  - **Learning-Based Methods**:
    - Implemented and evaluated two advanced AI-driven policies:
      - **Action Chunking with Transformers (ACT)**: Ensures smooth and coherent task execution.
      - **Diffusion Policies**: Focuses on precision and iterative trajectory refinement.
    - Applied to real-world tasks like pick-and-place, stacking, and object orientation.
  - Hardware and Software Innovations
    - Cost-effective hardware setup with dual RGB cameras and leader-follower robotic arms.
    - Integrated AI frameworks like **LeRobot** to train and evaluate learning-based policies.
    - Emphasized accessibility and scalability for educational and industrial applications.

> Dive deeper into this research on the [Research Page](research.md), featuring detailed videos, images, and technical insights.

## Work Experience

### Robotics Project Developer Intern – Kennedy Space Center Visitor Complex  
*(June 2024 – Current, Florida, USA)*  
- Designed and built a functional model of NASA’s Perseverance Rover using **Fusion 360** (mechanical, electronic, and programming).  
- Developed robust control systems for rover mobility and educational simulations; delivered a fully operational model under a tight timeline.

### Robotics Engineering Intern – Jaycon Systems  
*(Sep 2024 – Dec 2024, Melbourne, Florida)*  
- Designed and tested structural components for an augmented reality (AR) device.  
- Deployed **deep learning-based object detection** models on AR devices, enhancing real-time recognition capabilities.  
- Contributed to robotic arm automation projects, focusing on precision control algorithms.

### Robotics Engineer – BandG Robotics  
*(Jan 2021 – Dec 2022, Ahmedabad, India)*  
- Developed and programmed robotic manipulators using **ROS** and advanced control algorithms.  
- Designed custom end-effectors (Fusion 360 & SolidWorks) and optimized CNC manufacturing processes for robotic parts.

---

## Education

**Florida Institute of Technology**  
*MS in Mechanical Engineering (GPA 3.60/4.00)*  
*(Jan 2023 – Dec 2024)*

**Gujarat Technological University**  
*BE in Mechanical Engineering (GPA 3.50/4.00)*  
*(Aug 2017 – May 2021)*

---

## Skills
- **Programming:** Python, C/C++, PyTorch, ROS, Drake, OpenCV  
- **Robotics:** Computer Vision, Manipulation, Navigation, Imitation Learning, Deep Learning, Reinforcement Learning  
- **Simulation:** Isaac Sim, Gazebo, Drake  
- **CAD/CAM:** Fusion 360, SolidWorks, Ansys  

---

## Key Projects
### NASA’s Perseverance Rover Model
- **Tools**: Fusion 360, ROS, Python  
- **Highlight**: Developed a functional rover model with real-time control and sensor integration for educational demos.

### Augmented Reality Object Detection
- **Tools**: PyTorch, C++  
- **Highlight**: Implemented object detection on an AR device, enabling advanced user-interaction and immediate feedback.

---

*Thank you for visiting my portfolio! I look forward to connecting and exploring potential collaborations.*
